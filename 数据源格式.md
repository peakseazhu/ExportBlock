数据源格式
1.多源数据：地磁、地震波、大气电磁信号
2.1地磁波：分为两种格式：IAGA2002
IAGA2002又有两种文件类型：sec、min，其中文件.sec为秒级数据，文件.min为分钟级数据。
kak20200101dmin.min kak台站从2020年1月1日00:00:00开始，连续10个月分钟级数据
kak20200101psec.sec kak台站从2020年1月1日00:00:00开始，连续10个月秒级数据
地磁数据一共是3个台站：kak、kny、mmb，每个台站都有分钟级、秒级数据，共6个文件

2.2地震波格式：MiniSEED、SAC
MiniSEED最主流的格式一定要支持，SAC是可选的但也要有
MiniSEED格式，科研最常见类型，只含有波纹（波纹头端含有 台网+台站+位置+通道  如IC.ENH.00.BHZ），不包含台站的元数据（所在经纬度、用于空间匹配）
台站的元数据保存在xml文件中，一个xml文件包含多个台站元数据，miniseed文件波纹头端含有 台网+台站+位置+通道可以跟xml文件里的数据信息进行匹配，从而对应所对应的台站元数据。
stations_inventory.xml包含了6个台站的元数据
sac格式，含有波纹和台站的元数据(此处元数据是脚本下载数据时插入的，即sac自带台站的元数据)
get_data.py是下载地震波数据文件的脚本

2.3大气电磁信号
主要指大气中的电场（如近地面垂直电场/PG）以及大气/近地空间中的电磁波动（ELF/ULF/VLF 等频段的电磁扰动）。
这里分为两类：大气电磁、电磁波动vlf
2.3.1大气电场：kak20200101daef.min目录：kak台站从2020年1月1日00:00:00开始连续1年的分钟级数据，该目录下每一个文件是这期间每一天的分钟级数据
kak202001-202010daef.hor目录：kak台站从2020年1月1日00:00:00开始连续1年的分钟级数据，该目录下每一个文件时这期间每个月的小时级数据
2.3.2电磁波动：isee_vlf_mos_2020070712_v01.cdf 代表了mos台站在2020年7月7日12时的分钟级数据，该文件时间范围只有一个小时



1. 项目核心目标与可视化部分

首先，核心目标已经非常明确：实现多源数据处理、特征提取、事件关联与异常检测，并通过 API 提供查询功能。这是一个集中于数据处理和分析的项目，前端部分主要集中在 数据可视化展示。

1.1 任务和目标的衔接

该计划的核心任务是在 后端数据处理、分析与API接口提供，并不涉及复杂的前端交互。任务的重点是 多源数据处理、特征提取、事件关联和 异常标记，可视化仅是对分析结果的展示。通过 API 提供处理后的数据，特征以及分析结果，供后续前端展示使用。

数据处理：主要包括去噪、异常值剔除、缺失补全等工作，最终输出标准化数据（如 parquet 格式）和事件关联数据。

分析与特征提取：分析将聚焦于如何从不同的数据源中提取特征（如梯度、能量、频谱峰值等），并根据这些特征进行异常检测。

API接口：提供可以查询处理后的数据、特征及与地震事件关联的数据包。API 是后续前端展示的核心接口。

1.2 可视化部分的衔接

在该计划中，可视化展示更多地是通过查询接口进行，而不是开发一个复杂的前端系统。以下是几个关键点：

展示的数据：

原始数据：查询原始的地震、地磁、大气电磁等数据。

标准化数据：查询经过预处理（去噪、插值、异常剔除等）后的数据。

事件关联数据：查询与地震事件相关的数据（按时间窗和空间窗关联）。

特征数据：查询从原始数据中提取的特征，如地磁梯度、地震波能量、频谱峰值等。

异常标记：基于关联模型的输出，标记数据中的异常情况。

展示方式：

时间序列图：可以使用线图显示不同台站的地震波形数据，突出显示异常点。

空间分布图：展示不同台站在地震事件发生前后的数据响应。使用热力图或点图表示台站的位置和关联的异常值。

异常检测图：基于特征提取与关联模型输出的异常分数，可以展示不同事件、不同台站的异常检测结果。

频谱图：对电磁信号（AEF、VLF）进行频谱分析，展示信号频率分布、峰值等。

可视化将基于 API 查询到的数据进行展示，具体使用哪种图表可以根据项目需求与数据特点决定。一般而言，可以使用以下常见的图表：

折线图：用于展示时间序列数据，如地震波形。

热力图：展示空间数据，尤其是台站与地震事件的关联。

散点图：展示异常值的分布，可能是不同特征下的异常分数。

1.3 存储数据的方式

计划中提到的 数据存储格式 主要是 Parquet/HDF5，这两者都适合处理大规模数据，支持高效的读取和存储：

Parquet：列式存储格式，适合处理结构化数据，能高效地压缩数据并支持分区存储。这对于本项目中的时间序列数据存储和查询非常有效。

HDF5：适用于存储多维数据和大规模数据集，特别适用于科学计算中的数据存储。

这两种格式可以用于存储处理后的数据、特征、事件关联数据等。

1.4 可视化的实际执行方式

可视化部分可以由以下组件来完成：

数据查询接口：通过提供的 API，前端可以查询到 parquet 格式的标准化数据和特征数据。

前端可视化：前端可以使用 JavaScript 数据可视化库（如 D3.js、Plotly 或 Leaflet）来展示查询到的数据。

分析展示：基于前端的 API 查询，用户可以查看事件关联数据、特征数据和异常检测结果。前端可以根据这些数据生成时间序列图、空间分布图和异常标记图。

1.5 不需要过于复杂的前端展示

正如你所说，不需要做得太复杂，前端展示应该简洁明了，重点在于展示 地震事件的特征、异常以及与事件的关联性。可视化应该：

简单展示每个台站与地震事件的关联情况。

展示特征提取结果，如梯度变化、频谱分析结果等。

可视化异常检测结果，帮助研究人员和工程师快速识别可能的异常信号。

2. 数据存储与展示建议

存储方式：

使用 Parquet 格式存储原始数据、标准化数据、特征、事件关联数据。由于数据结构化且较大，Parquet 的列式存储适合快速查询和数据压缩。

对于需要快速处理和读取的小规模数据，可以使用 HDF5。

可视化展示的关键图表：

时间序列图（用于地震波、地磁信号等）

空间分布图（展示台站分布与异常值）

异常检测图（基于模型输出的异常分数进行展示）

频谱图（展示电磁数据的频率分布）

工具：

后端：使用 FastAPI 提供查询接口，支持数据查询、特征提取查询、事件关联数据查询等。

前端：前端可以通过查询 API，使用 Plotly、D3.js 、echarts等库来呈现时间序列、频谱图、空间图等数据。

3. 总结与建议

核心目标：数据处理和特征提取是最核心的工作，重点在于将多源数据处理成标准格式，提取出有效的特征，并建立基于这些特征的简单异常检测模型。

可视化部分：不需要过于复杂的图形展示，重点在于将处理结果通过图表展示出来。时间序列图、空间分布图和异常检测图是比较合理的展示方式。

存储与查询：选择 Parquet 格式来存储数据，前端通过 API 查询获取数据，并使用 D3.js 或 Plotly 、echarts库展示数据。
最终的项目形态是 后端的数据处理与分析系统，通过 API 提供数据查询，前端展示模块利用这些查询结果展示图表，帮助研究人员理解数据并识别异常。
